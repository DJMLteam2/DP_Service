{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pickle\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from konlpy.tag import Okt\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'list' object has no attribute 'tolist'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m/home/doxg/code/DP_Service/python/test.ipynb Cell 2\u001b[0m line \u001b[0;36m2\n\u001b[1;32m      <a href='vscode-notebook-cell://wsl%2Bubuntu/home/doxg/code/DP_Service/python/test.ipynb#X52sdnNjb2RlLXJlbW90ZQ%3D%3D?line=0'>1</a>\u001b[0m sor \u001b[39m=\u001b[39m [\u001b[39m3512\u001b[39m, \u001b[39m5882\u001b[39m, \u001b[39m1963\u001b[39m, \u001b[39m1955\u001b[39m, \u001b[39m1956\u001b[39m]\n\u001b[0;32m----> <a href='vscode-notebook-cell://wsl%2Bubuntu/home/doxg/code/DP_Service/python/test.ipynb#X52sdnNjb2RlLXJlbW90ZQ%3D%3D?line=1'>2</a>\u001b[0m sor\u001b[39m.\u001b[39;49mtolist()\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'list' object has no attribute 'tolist'"
     ]
    }
   ],
   "source": [
    "sor = [3512, 5882, 1963, 1955, 1956]\n",
    "sor.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = ['andf', 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['andf', 1]\n"
     ]
    }
   ],
   "source": [
    "print((str(test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "okt = Okt()\n",
    "df = pd.read_csv('./travel_spot_v1.csv')\n",
    "df['tf'] = df['tagName'] + df['treatMenu']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.fillna('')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unnamed: 0     0\n",
      "id             0\n",
      "city           0\n",
      "cityCode       0\n",
      "contentType    0\n",
      "title          0\n",
      "catchtitle     0\n",
      "overView       0\n",
      "treatMenu      0\n",
      "conLike        0\n",
      "conRead        0\n",
      "conShare       0\n",
      "imgPath        0\n",
      "addr           0\n",
      "info           0\n",
      "parking        0\n",
      "useTime        0\n",
      "tagName        0\n",
      "detail         0\n",
      "lat            0\n",
      "lon            0\n",
      "tf             0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(df.isna().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Iterable over raw text documents expected, string object received.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m/home/doxg/code/DP_Service/python/test.ipynb Cell 8\u001b[0m line \u001b[0;36m7\n\u001b[1;32m      <a href='vscode-notebook-cell://wsl%2Bubuntu/home/doxg/code/DP_Service/python/test.ipynb#X10sdnNjb2RlLXJlbW90ZQ%3D%3D?line=4'>5</a>\u001b[0m B \u001b[39m=\u001b[39m [i \u001b[39mfor\u001b[39;00m i \u001b[39min\u001b[39;00m okt\u001b[39m.\u001b[39mmorphs(b) \u001b[39mif\u001b[39;00m \u001b[39mlen\u001b[39m(i) \u001b[39m>\u001b[39m\u001b[39m1\u001b[39m]\n\u001b[1;32m      <a href='vscode-notebook-cell://wsl%2Bubuntu/home/doxg/code/DP_Service/python/test.ipynb#X10sdnNjb2RlLXJlbW90ZQ%3D%3D?line=5'>6</a>\u001b[0m vectorizer \u001b[39m=\u001b[39m TfidfVectorizer()\n\u001b[0;32m----> <a href='vscode-notebook-cell://wsl%2Bubuntu/home/doxg/code/DP_Service/python/test.ipynb#X10sdnNjb2RlLXJlbW90ZQ%3D%3D?line=6'>7</a>\u001b[0m text \u001b[39m=\u001b[39m vectorizer_spot\u001b[39m.\u001b[39;49mtransform(a)\n\u001b[1;32m      <a href='vscode-notebook-cell://wsl%2Bubuntu/home/doxg/code/DP_Service/python/test.ipynb#X10sdnNjb2RlLXJlbW90ZQ%3D%3D?line=8'>9</a>\u001b[0m cosine_similarity(text, matrix_spot)\n",
      "File \u001b[0;32m~/.pyenv/versions/3.8.18/lib/python3.8/site-packages/sklearn/feature_extraction/text.py:2163\u001b[0m, in \u001b[0;36mTfidfVectorizer.transform\u001b[0;34m(self, raw_documents)\u001b[0m\n\u001b[1;32m   2146\u001b[0m \u001b[39m\u001b[39m\u001b[39m\"\"\"Transform documents to document-term matrix.\u001b[39;00m\n\u001b[1;32m   2147\u001b[0m \n\u001b[1;32m   2148\u001b[0m \u001b[39mUses the vocabulary and document frequencies (df) learned by fit (or\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   2159\u001b[0m \u001b[39m    Tf-idf-weighted document-term matrix.\u001b[39;00m\n\u001b[1;32m   2160\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m   2161\u001b[0m check_is_fitted(\u001b[39mself\u001b[39m, msg\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mThe TF-IDF vectorizer is not fitted\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m-> 2163\u001b[0m X \u001b[39m=\u001b[39m \u001b[39msuper\u001b[39;49m()\u001b[39m.\u001b[39;49mtransform(raw_documents)\n\u001b[1;32m   2164\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_tfidf\u001b[39m.\u001b[39mtransform(X, copy\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m)\n",
      "File \u001b[0;32m~/.pyenv/versions/3.8.18/lib/python3.8/site-packages/sklearn/feature_extraction/text.py:1428\u001b[0m, in \u001b[0;36mCountVectorizer.transform\u001b[0;34m(self, raw_documents)\u001b[0m\n\u001b[1;32m   1412\u001b[0m \u001b[39m\u001b[39m\u001b[39m\"\"\"Transform documents to document-term matrix.\u001b[39;00m\n\u001b[1;32m   1413\u001b[0m \n\u001b[1;32m   1414\u001b[0m \u001b[39mExtract token counts out of raw text documents using the vocabulary\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1425\u001b[0m \u001b[39m    Document-term matrix.\u001b[39;00m\n\u001b[1;32m   1426\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m   1427\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(raw_documents, \u001b[39mstr\u001b[39m):\n\u001b[0;32m-> 1428\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[1;32m   1429\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mIterable over raw text documents expected, string object received.\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m   1430\u001b[0m     )\n\u001b[1;32m   1431\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_check_vocabulary()\n\u001b[1;32m   1433\u001b[0m \u001b[39m# use the same matrix-building strategy as fit_transform\u001b[39;00m\n",
      "\u001b[0;31mValueError\u001b[0m: Iterable over raw text documents expected, string object received."
     ]
    }
   ],
   "source": [
    "okt = Okt()\n",
    "a = \"샥스핀, 식사류해삼류,단품 요리 바닷가재 등  짬뽕 등  등\"\n",
    "b = \"샥스핀, 해삼류, 바닷가재 등 단품 요리, 짜장면, 짬뽕 등 식사류 등\"\n",
    "A = [i for i in okt.morphs(a) if len(i) >1]\n",
    "B = [i for i in okt.morphs(b) if len(i) >1]\n",
    "vectorizer = TfidfVectorizer()\n",
    "text = vectorizer_spot.transform(a)\n",
    "\n",
    "cosine_similarity(text, matrix_spot)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'가족여행,걷기길,관광지,데이트코스,반려동물동반여행지,생태관광지,서울숲,수도권,수도권반려동물여행지,아이와함께,연인과함께,연중무휴,피크닉,한국관광100선,휴식공간,휴식여행,휴식하기,휴식하기좋은곳'"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[df['contentType'] != 39]['tagName'][195]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['city'] = '전체'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2 = pd.read_csv('./travel_spot_v1.csv')\n",
    "df2['tf'] = df2['tagName'] + df2['treatMenu']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "df3 = pd.concat([df,df2], axis=0, ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "df3 = df3[['id', 'city', 'cityCode', 'contentType', 'title',\n",
    "       'catchtitle', 'overView', 'treatMenu', 'conLike', 'conRead', 'conShare',\n",
    "       'imgPath', 'addr', 'info', 'parking', 'useTime', 'tagName', 'detail',\n",
    "       'lat', 'lon', 'tf']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "df3.to_csv('travel_spot_v1.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "spot_df = df3[df3['contentType'] != 39]\n",
    "food_df = df3[df3['contentType'] == 39]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(9268, 11766, 21034)"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(spot_df), len(food_df), len(df3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorizer_spot = TfidfVectorizer()\n",
    "\n",
    "tag_list = [' '.join([j for j in okt.morphs(i) if len(j) > 1]) for i in spot_df['tagName'].tolist()]\n",
    "matrix_spot = vectorizer_spot.fit_transform(tag_list)\n",
    "\n",
    "# 각 지역에 대한 TF-IDF 행렬 계산\n",
    "city_matrices_spot = {}    \n",
    "for city in spot_df['city'].unique():\n",
    "    city_df = spot_df[spot_df['city'] == city]\n",
    "    city_tag_list = [' '.join([j for j in okt.morphs(i) if len(j) > 1]) for i in city_df['tagName'].tolist()]\n",
    "    city_matrices_spot[city] = vectorizer_spot.transform(city_tag_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorizer_food = TfidfVectorizer()\n",
    "\n",
    "tag_list = [' '.join([j for j in okt.morphs(str(i)) if len(j) > 1]) for i in food_df['tf'].tolist()]\n",
    "matrix_food = vectorizer_food.fit_transform(tag_list)\n",
    "\n",
    "# 각 지역에 대한 TF-IDF 행렬 계산\n",
    "city_matrices_food = {}    \n",
    "for city in food_df['city'].unique():\n",
    "    city_df = food_df[food_df['city'] == city]\n",
    "    city_tag_list = [' '.join([j for j in okt.morphs(str(i)) if len(j) > 1]) for i in city_df['tf'].tolist()]\n",
    "    city_matrices_food[city] = vectorizer_food.transform(city_tag_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# 저장\n",
    "with open('travel_model_v2.pkl', 'wb') as file:\n",
    "        pickle.dump({\"spot\":{\n",
    "                \"vectorizer\": vectorizer_spot,\n",
    "                \"matrix\": matrix_spot,\n",
    "                \"city_matrices\": city_matrices_spot\n",
    "        },\"food\":{\n",
    "                \"vectorizer\": vectorizer_food,\n",
    "                \"matrix\": matrix_food,\n",
    "                \"city_matrices\": city_matrices_food\n",
    "        }}, file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('./travel_model_v2.pkl', 'rb') as file:\n",
    "    loaded_data = pickle.load(file)\n",
    "    \n",
    "    vectorizer_spot = loaded_data[\"spot\"][\"vectorizer\"]\n",
    "    matrix_spot = loaded_data[\"spot\"][\"matrix\"]\n",
    "    city_matrices_spot = loaded_data[\"spot\"][\"city_matrices\"]\n",
    "\n",
    "    vectorizer_food = loaded_data[\"food\"][\"vectorizer\"]\n",
    "    matrix_food = loaded_data[\"food\"][\"matrix\"]\n",
    "    city_matrices_food = loaded_data[\"food\"][\"city_matrices\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#     # 미리 계산된 해당 지역의 TF-IDF 행렬 사용\n",
    "# if question.area == '전체':\n",
    "#     city_tfidf_matrix = tfidf_matrix\n",
    "# else:\n",
    "#     city_tfidf_matrix = city_tfidf_matrices.get(question.area)\n",
    "#     df = df[df['city']== f'{question.area}']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<351x5323 sparse matrix of type '<class 'numpy.float64'>'\n",
       "\twith 5212 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "city_matrices_spot['충남']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'spot_df' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m/home/doxg/code/DP_Service/python/test.ipynb Cell 23\u001b[0m line \u001b[0;36m4\n\u001b[1;32m      <a href='vscode-notebook-cell://wsl%2Bubuntu/home/doxg/code/DP_Service/python/test.ipynb#X31sdnNjb2RlLXJlbW90ZQ%3D%3D?line=0'>1</a>\u001b[0m area \u001b[39m=\u001b[39m \u001b[39m'\u001b[39m\u001b[39m인천\u001b[39m\u001b[39m'\u001b[39m\n\u001b[1;32m      <a href='vscode-notebook-cell://wsl%2Bubuntu/home/doxg/code/DP_Service/python/test.ipynb#X31sdnNjb2RlLXJlbW90ZQ%3D%3D?line=1'>2</a>\u001b[0m question \u001b[39m=\u001b[39m \u001b[39m'\u001b[39m\u001b[39m캠핑\u001b[39m\u001b[39m'\u001b[39m\n\u001b[0;32m----> <a href='vscode-notebook-cell://wsl%2Bubuntu/home/doxg/code/DP_Service/python/test.ipynb#X31sdnNjb2RlLXJlbW90ZQ%3D%3D?line=3'>4</a>\u001b[0m df \u001b[39m=\u001b[39m spot_df[spot_df[\u001b[39m'\u001b[39m\u001b[39mcity\u001b[39m\u001b[39m'\u001b[39m]\u001b[39m==\u001b[39m \u001b[39mf\u001b[39m\u001b[39m'\u001b[39m\u001b[39m{\u001b[39;00marea\u001b[39m}\u001b[39;00m\u001b[39m'\u001b[39m]\n\u001b[1;32m      <a href='vscode-notebook-cell://wsl%2Bubuntu/home/doxg/code/DP_Service/python/test.ipynb#X31sdnNjb2RlLXJlbW90ZQ%3D%3D?line=5'>6</a>\u001b[0m question_tfidf \u001b[39m=\u001b[39m vectorizer_spot\u001b[39m.\u001b[39mtransform(okt\u001b[39m.\u001b[39mmorphs(\u001b[39mf\u001b[39m\u001b[39m'\u001b[39m\u001b[39m{\u001b[39;00mquestion\u001b[39m}\u001b[39;00m\u001b[39m'\u001b[39m))\n\u001b[1;32m      <a href='vscode-notebook-cell://wsl%2Bubuntu/home/doxg/code/DP_Service/python/test.ipynb#X31sdnNjb2RlLXJlbW90ZQ%3D%3D?line=7'>8</a>\u001b[0m cos_similarities \u001b[39m=\u001b[39m cosine_similarity(question_tfidf, city_matrices_spot[\u001b[39mf\u001b[39m\u001b[39m'\u001b[39m\u001b[39m{\u001b[39;00marea\u001b[39m}\u001b[39;00m\u001b[39m'\u001b[39m])\n",
      "\u001b[0;31mNameError\u001b[0m: name 'spot_df' is not defined"
     ]
    }
   ],
   "source": [
    "area = '인천'\n",
    "question = '캠핑'\n",
    "\n",
    "df = spot_df[spot_df['city']== f'{area}']\n",
    "\n",
    "question_tfidf = vectorizer_spot.transform(okt.morphs(f'{question}'))\n",
    "\n",
    "cos_similarities = cosine_similarity(question_tfidf, city_matrices_spot[f'{area}'])\n",
    "sorted_indices = np.argsort(cos_similarities[0])[::-1][:5]\n",
    "print('indices= ',len(sorted_indices))\n",
    "print('df= ', len(df))\n",
    "# 식당인 것, 아닌 \n",
    "\n",
    "index = sorted_indices[0]\n",
    "\n",
    "\n",
    "\n",
    "print(\n",
    "str(df.iloc[index]['id']),\n",
    "str(df.iloc[index]['city']),\n",
    "str(df.iloc[index]['title']),\n",
    "float(cos_similarities[0][index]),\n",
    "str(df.iloc[index]['catchtitle']))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "indices=  5\n",
      "df=  192\n",
      "2866244 대구 루미너스 0.42204924949455175 모던한 분위기의 한우 안심 스테이크 맛집\n"
     ]
    }
   ],
   "source": [
    "area = '대구'\n",
    "question = '피자'\n",
    "\n",
    "df = food_df[food_df['city']== f'{area}']\n",
    "\n",
    "question_tfidf = vectorizer_food.transform(okt.morphs(f'{question}'))\n",
    "\n",
    "cos_similarities = cosine_similarity(question_tfidf, city_matrices_food[f'{area}'])\n",
    "sorted_indices = np.argsort(cos_similarities[0])[::-1][:5]\n",
    "print('indices= ',len(sorted_indices))\n",
    "print('df= ', len(df))\n",
    "# 식당인 것, 아닌 \n",
    "\n",
    "index = sorted_indices[0]\n",
    "\n",
    "\n",
    "\n",
    "print(\n",
    "str(df.iloc[index]['id']),\n",
    "str(df.iloc[index]['city']),\n",
    "str(df.iloc[index]['title']),\n",
    "float(cos_similarities[0][index]),\n",
    "str(df.iloc[index]['catchtitle']))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "63"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.argsort(cos_similarities[0])[::-1][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.30805653331899097"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cos_similarities[0][63]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('./travel_spot_v1.csv', index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "okt = Okt()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "여기여기\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "352"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "question_area = '인천'\n",
    "question_question = '효도여행'\n",
    "\n",
    "# 미리 계산된 해당 지역의 TF-IDF 행렬 사용\n",
    "if question_area == '전체':\n",
    "    city_tfidf_matrix = tfidf_matrix\n",
    "else:\n",
    "    city_tfidf_matrix = city_tfidf_matrices.get(question_area)\n",
    "    df = df[df['city']== f'{question_area}']\n",
    "\n",
    "print('여기여기')\n",
    "\n",
    "if city_tfidf_matrix is None:\n",
    "    print(JSONResponse(content={\"error\": f\"No data found for city: {question_area}\"}, status_code=404))\n",
    "\n",
    "# 질문과 선택된 지역의 TF-IDF로 유사도 계산\n",
    "question_tfidf = tfidf_vectorizer.transform(okt.morphs(question_question))\n",
    "cos_similarities = cosine_similarity(question_tfidf, city_tfidf_matrix)\n",
    "sorted_indices = np.argsort(cos_similarities[0])[::-1]\n",
    "len(sorted_indices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "([111, 112, 113, 114, 115], [351, 350, 296, 288, 289])"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "restaurant = sorted_indices[df.iloc[sorted_indices]['contentType'].eq(39)].tolist()[:5]\n",
    "non_restaurant = sorted_indices[~df.iloc[sorted_indices]['contentType'].eq(39)].tolist()[:5]\n",
    "\n",
    "restaurant,non_restaurant"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(352, 352)"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(df), len(sorted_indices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "352"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(sorted_indices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "여기여기2\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "([111, 112, 113, 114, 115], [351, 350, 296, 288, 289])"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "print('여기여기2')\n",
    "\n",
    "from itertools import islice\n",
    "# 식당인 것, 아닌 것\n",
    "restaurant = islice((index for index in sorted_indices if df.iloc[index]['contentType'] == 39 ), 5)\n",
    "non_restaurant = islice((index for index in sorted_indices if df.iloc[index]['contentType'] != 39 ), 5)\n",
    "\n",
    "list(restaurant), list(non_restaurant)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'인천'"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "str(df.iloc[111]['city'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2758144'"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "str(df.iloc[111]['id'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_to_similar_tags(sorted_indices,similar_tags):\n",
    "    bag = []\n",
    "    for index in sorted_indices:\n",
    "        print(\"Current index:\", index)\n",
    "        bag.append({\n",
    "            \"id\": str(df.iloc[index]['id']),\n",
    "            \"area\": str(df.iloc[index]['city'])})\n",
    "        similar_tags.append(bag)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<itertools.islice at 0x7f1b75d94950>"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "restaurant\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "여기여기 3\n",
      "여기여기4\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[[], []]"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "# 결과를 저장할 리스트 초기화\n",
    "similar_tags = []\n",
    "print('여기여기 3')\n",
    "# 리스트로 추가\n",
    "def add_to_similar_tags(sorted_indices,similar_tags):\n",
    "    bag = []\n",
    "    for index in sorted_indices:\n",
    "        print(\"Current index:\", index)\n",
    "        bag.append({\n",
    "            \"id\": str(df.iloc[index]['id']),\n",
    "            \"area\": str(df.iloc[index]['city']),\n",
    "            \"title\": str(df.iloc[index]['title']),\n",
    "            \"similarity\": float(cos_similarities[0][index]),\n",
    "            \"catchtitle\": str(df.iloc[index]['catchtitle']),\n",
    "            # \"detail\": str(df.iloc[index]['detail']),\n",
    "            \"treatMenu\": str(df.iloc[index]['treatMenu']),\n",
    "            \"tagName\": str(df.iloc[index]['tagName']),\n",
    "            \"addr\": str(df.iloc[index]['addr']),\n",
    "            \"info\": str(df.iloc[index]['info']),\n",
    "            # \"lat\": str(df.iloc[index]['parking']),\n",
    "            \"useTime\": str(df.iloc[index]['useTime']),\n",
    "            \"conLike\": str(df.iloc[index]['conLike']),\n",
    "            \"conRead\": str(df.iloc[index]['conRead']),\n",
    "            \"conShare\": str(df.iloc[index]['conShare']),\n",
    "            # \"overView\": str(df.iloc[index]['overView']),\n",
    "            \"lat\": str(df.iloc[index]['lat']),\n",
    "            \"lon\": str(df.iloc[index]['lon'])\n",
    "            \n",
    "            })\n",
    "    similar_tags.append(bag)\n",
    "print('여기여기4')\n",
    "\n",
    "# 함수를 사용\n",
    "add_to_similar_tags(non_restaurant,similar_tags)\n",
    "add_to_similar_tags(restaurant,similar_tags)\n",
    "similar_tags"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "352"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sorted_indices.__len__()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sorted_indices length: 0\n",
      "Adding bag to similar_tags: []\n",
      "sorted_indices length: 0\n",
      "Adding bag to similar_tags: []\n",
      "Final similar_tags: [[], []]\n"
     ]
    }
   ],
   "source": [
    "# 결과를 저장할 리스트 초기화\n",
    "similar_tags = []\n",
    "\n",
    "def add_to_similar_tags(sorted_indices):\n",
    "    bag = []\n",
    "    sorted_indices = list(sorted_indices)[:len(df)]\n",
    "    print(\"sorted_indices length:\", len(sorted_indices))\n",
    "    for index in sorted_indices:\n",
    "        print(\"Processing index:\", index)\n",
    "        if 0 <= index < len(df):\n",
    "            print(\"Adding to bag:\", index)\n",
    "            bag.append({\n",
    "                \"id\": str(df.iloc[index]['id']),\n",
    "                \"area\": str(df.iloc[index]['city']),\n",
    "                \"title\": str(df.iloc[index]['title']),\n",
    "                \"similarity\": float(cos_similarities[0][index]),\n",
    "                \"catchtitle\": str(df.iloc[index]['catchtitle']),\n",
    "                \"treatMenu\": str(df.iloc[index]['treatMenu']),\n",
    "                \"tagName\": str(df.iloc[index]['tagName']),\n",
    "                \"addr\": str(df.iloc[index]['addr']),\n",
    "                \"info\": str(df.iloc[index]['info']),\n",
    "                \"useTime\": str(df.iloc[index]['useTime']),\n",
    "                \"conLike\": str(df.iloc[index]['conLike']),\n",
    "                \"conRead\": str(df.iloc[index]['conRead']),\n",
    "                \"conShare\": str(df.iloc[index]['conShare']),\n",
    "                \"lat\": str(df.iloc[index]['lat']),\n",
    "                \"lon\": str(df.iloc[index]['lon'])\n",
    "            })\n",
    "        else:\n",
    "            print(\"Index out of bounds:\", index)\n",
    "    print(\"Adding bag to similar_tags:\", bag)\n",
    "    similar_tags.append(bag)\n",
    "\n",
    "# 함수를 사용\n",
    "add_to_similar_tags(non_restaurant)\n",
    "add_to_similar_tags(restaurant)\n",
    "\n",
    "print(\"Final similar_tags:\", similar_tags)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
